getwd()
setwd("/Users/y0u3k2o5/Library/CloudStorage/OneDrive-MichiganStateUniversity/2024-2025/Eye-tracking Project")
rm(list=ls()) #clear environment

#import the data
library(haven)

# Load necessary libraries
install.packages("readxl")      # Only once
library(readxl)

########################################
####1.Comprehension Questions####
#######################################
# List all sheet names
excel_sheets("Comprehension Question_Scoring.xlsx")

# Read a specific sheet by name
comprQ <- read_excel("Comprehension Question_Scoring.xlsx", sheet = "All_Score")
summary(comprQ[, c("Positive", "Neutral", "Negative")])


#Make a long format
library(tidyverse)
library(reshape2)
comprQ_long <- melt(comprQ, id.vars = "Participant")
names(comprQ_long) <- c("Participant", "Emotion", "Score")
View(comprQ_long)


### Discriptive Analaysis with the Long Format###
#descriptive statistics
library(psych)
psych::describeBy(comprQ_long$Score, group = comprQ_long$Emotion)

library(ggplot2)

##NO Color Outliers, Big fonts##
p2 <- ggplot(comprQ_long, aes(x = Emotion, y = Score)) + 
  geom_boxplot() + 
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(name = "Score", breaks = seq(0, 17, 2), limits = c(0, 17)) + 
  scale_x_discrete(name = "Text Type") + 
  labs(title = "Comprehension Questions") + 
  theme(
    plot.title = element_text(size = 22, face = "bold", hjust = 0.5),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14)
  )
print(p2)

##Shapiro-Wilk Normality Test (Just In Case)##
shapiro.test(compr_long$Score[compr_long$Emotion == "Negative"])
shapiro.test(compr_long$Score[compr_long$Emotion == "Neutral"])
shapiro.test(compr_long$Score[compr_long$Emotion == "Positive"])

#Levene's test 0.32
car::leveneTest(Score ~ Emotion, data = compr_long, center = median) #Statisrically not-significant

##Within-Participant Design RM ANOVA###
library(ez)
ez_results <- ezANOVA(
  data = compr_long,
  dv = .(Score),
  wid = .(Participant),
  within = .(Emotion),          # ✅ CHANGED from between to within
  type = 2,
  return_aov = TRUE,
  detailed = TRUE
)
print(ez_results)

##T-test
pairwise.t.test(x = compr_long$Score,      # DV: comprehension scores
                g = compr_long$Emotion,   # Grouping variable
                paired = TRUE,            # Not repeated measures
                p.adj = "bonf")            # Bonferroni correction


##Effect Sizes for Each Text (Session 1 +Session 2 Combined)##
library(tidyverse)
library(effsize)

# Negative vs Neutral
data_neg_vs_neu <- compr_long %>%
  filter(Emotion %in% c("Negative", "Neutral")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_neu$Score, data_neg_vs_neu$Emotion, paired = TRUE)

# Negative vs Positive
data_neg_vs_pos <- compr_long %>%
  filter(Emotion %in% c("Negative", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_pos$Score, data_neg_vs_pos$Emotion, paired = TRUE)

# Negative vs Neutral
data_neu_vs_pos <- compr_long %>%
  filter(Emotion %in% c("Neutral", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neu_vs_pos$Score, data_neu_vs_pos$Emotion, paired = TRUE)


########################################
####2.Emotionality Ratings####
#######################################

# List all sheet names
excel_sheets("Emotionality Rating & Self-Assessment Manekins.xlsx")

#1.1 Emotionality Ratings
# Read a specific sheet by name
emotion <- read_excel("Emotionality Rating & Self-Assessment Manekins.xlsx", sheet = "Emotionality Rating")

#descriptive statistics
install.packages("psych")
library(psych)
describeBy(emotion$Response, group = emotion$Emotion)

###BoxPlots: NO Outlier Color###
library(ggplot2)

p1 <- ggplot(compr_long, aes(x = TextType, y = Score)) + 
  geom_boxplot(outlier.shape = NA) +  # Removes default black outlier dots
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(name = "Score", breaks = seq(0, 17, 2), limits = c(0, 17)) + 
  scale_x_discrete(name = "Text Type") + 
  labs(title = "Comprehension Questions") + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )

print(p1)

#1.2 Valence
# Read a specific sheet by name
valence <- read_excel("Emotionality Rating & Self-Assessment Manekins.xlsx", sheet = "Valence")

#descriptive statistics
install.packages("psych")
library(psych)
describeBy(valence$Response, group = valence$Emotion)

library(ggplot2)

###BoxPlots: NO Outlier Color###

p1 <- ggplot(valence, aes(x = Emotion, y = Response)) + 
  geom_boxplot(outlier.shape = NA) +  # removes default black outliers
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(
    name = "Response", 
    breaks = seq(1, 9, 2), 
    limits = c(1, 9)
  ) + 
  scale_x_discrete(name = "Text Type") + 
  labs(title = "Valence") + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )

print(p1)


#1.3 Arousal
# Read a specific sheet by name
arousal <- read_excel("Emotionality Rating & Self-Assessment Manekins.xlsx", sheet = "Arousal")

#descriptive statistics
install.packages("psych")
library(psych)
describeBy(arousal$Response, group = arousal$Emotion)

###BoxPlots: NO Outlier Color###

library(ggplot2)

p1 <- ggplot(arousal, aes(x = Emotion, y = Response)) + 
  geom_boxplot(outlier.shape = NA) +  # removes default black outliers
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(
    name = "Response", 
    breaks = seq(1, 9, 2), 
    limits = c(1, 9)
  ) + 
  scale_x_discrete(name = "Text Type") + 
  labs(title = "Arousal") + 
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )

print(p1)

########################################
####3.Vocabulary Tests####
#######################################

##3.1 Meaning Recognition

# List all sheet names
excel_sheets("Scoring_Multiple_Choice.xlsx")

# Read a specific sheet by name
VocabMultiple <- read_excel("Scoring_Multiple_Choice.xlsx", sheet = "All_Score")

#Make a long format
library(tidyverse)
library(reshape2)
VocabMultiple_long<- reshape2::melt(VocabMultiple, id = c('Participant', 'Emotion')) 
names(VocabMultiple_long)[3:4] <- c('Session', 'Score')
View(VocabMultiple_long)

# Descriptive statistics grouped by TextType and Session
library(psych)
psych::describeBy(VocabMultiple_long$Score, 
           group = list(VocabMultiple_long$Emotion, VocabMultiple_long$Session))

# BoxPlots 2 (Updated) NO OULIER COLOR, Change the Session name and make fonts bigger
library(ggplot2)
p2 <- ggplot(VocabMultiple_long, aes(x = Emotion, y = Score)) + 
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(name = "Score", breaks = seq(0, 18, 2), limits = c(0, 18)) + 
  scale_x_discrete(name = "Text Type") + 
  facet_wrap(~ Session,
             labeller = as_labeller(c(
               "Session 1" = "Immediate Post-test",
               "Session 2" = "Delayed Post-test"
             ))) +
  labs(title = "Meaning Recognition") + 
  theme(
    plot.title = element_text(size = 22, face = "bold", hjust = 0.5),
    strip.text = element_text(size = 18, face = "bold"),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14)
  )

print(p2)

### How can we show p-value* and effect sizes? In-Progress####

##Shapiro-Wilk Normality Test (Just In Case)##
# Shapiro-Wilk for Session 1 by Emotion
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Negative", ]$`Session 1`)  # < .001***
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Neutral", ]$`Session 1`)   # < .001***
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Positive", ]$`Session 1`)  # < .001***

# Shapiro-Wilk for Session 2 by Emotion
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Negative", ]$`Session 2`)  # p = 0.002
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Neutral", ]$`Session 2`)   # p = 0.035
shapiro.test(VocabMultiple[VocabMultiple$Emotion == "Positive", ]$`Session 2`)  # p = 0.001

# Levene's tests
# 1. Levene's Test across Sessions (Session 1 vs Session 2) # p =  0.0002952 ***
car::leveneTest(VocabMultiple_long$Score, VocabMultiple_long$Session, center = median)
# 2. Levene's Test across Emotions (Negative / Neutral / Positive) # p = 0.698
car::leveneTest(VocabMultiple_long$Score, VocabMultiple_long$Emotion, center = median)
# 3. Levene's Test across Emotion × Session combinations # p = 0.04396 *
car::leveneTest(VocabMultiple_long$Score, interaction(VocabMultiple_long$Emotion, VocabMultiple_long$Session), center = median)


### Within (Emotion) x Within (Session) (RM ANOVA) ####

library(ez)

ez_results <- ezANOVA(
  data = VocabMultiple_long,              # e.g., VocabMultiple_long
  dv = .(Score),                 
  wid = .(Participant),          
  within = .(Emotion, Session),     # ✅ Two within-subjects factors
  type = 2,
  return_aov = TRUE,
  detailed = TRUE
)

print(ez_results)


###T-test Session 1 + Session 2 Combined###

# Step 1: Filter Session 1 and 2
data_s1s2 <- VocabMultiple_long %>%
  filter(Session %in% c("Session 1", "Session 2"))

# Step 2: Sum scores across sessions for each Participant × Emotion
combined_scores <- data_s1s2 %>%
  group_by(Participant, Emotion) %>%
  summarise(Score = sum(Score), .groups = "drop")

# Step 3: Pairwise t-test
pairwise.t.test(
  x = combined_scores$Score,
  g = combined_scores$Emotion,
  paired = TRUE,
  p.adjust.method = "bonferroni"
)

##Effect Sizes for Each Text (Session 1 +Session 2 Combined)##
library(tidyverse)
library(effsize)

# Negative vs Neutral
data_neg_vs_neu <- combined_scores %>%
  filter(Emotion %in% c("Negative", "Neutral")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_neu$Score, data_neg_vs_neu$Emotion, paired = TRUE)

# Negative vs Positive
data_neg_vs_pos <- combined_scores %>%
  filter(Emotion %in% c("Negative", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_pos$Score, data_neg_vs_pos$Emotion, paired = TRUE)

# Negative vs Neutral
data_neu_vs_pos <- combined_scores %>%
  filter(Emotion %in% c("Neutral", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neu_vs_pos$Score, data_neu_vs_pos$Emotion, paired = TRUE)

##Check potential outliers##
# Save standardized residuals
model_vocab <- lm(Score ~ Emotion * Session, data = VocabMultiple_long)
VocabMultiple_long$standres_vocab <- rstandard(model_vocab)
#>3#
# Number of outliers
sum(abs(VocabMultiple_long$standres_vocab) > 3)
# Row indices of outliers
which(abs(VocabMultiple_long$standres_vocab) > 3)
# View full rows of those outliers
VocabMultiple_long[which(abs(VocabMultiple_long$standres_vocab) > 3), ]

##########################
##3.2 Form Recognition##

# List all sheet names
excel_sheets("Scoring_Form_Recognition.xlsx")

# Read a specific sheet by name
FormRecognition <- read_excel("Scoring_Form_Recognition.xlsx", sheet = "All_Score")

#Make a long format
library(tidyverse)
library(reshape2)
FormRecognition_long <- reshape2::melt(FormRecognition, id = c('Participant', 'Emotion')) 
names(FormRecognition_long)[3:4] <- c('Session', 'Score')
View(FormRecognition_long)

# Descriptive statistics grouped by TextType and Session
library(psych)
psych::describeBy(FormRecognition_long$Score, 
                  group = list(FormRecognition_long$Emotion, FormRecognition_long$Session))

# BoxPlots
library(ggplot2)

# BoxPlots 2 (Updated) NO OULIER COLOR, Change the Session name and make fonts bigger
library(ggplot2)
p2 <- ggplot(FormRecognition_long, aes(x = Emotion, y = Score)) + 
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter(color = "#008208", width = 0.4, height = 0, size = 2, alpha = 0.6) + 
  stat_summary(fun = mean, geom = "point", color = "blue", size = 3) +
  scale_y_continuous(name = "Score", breaks = seq(0, 18, 2), limits = c(0, 18)) + 
  scale_x_discrete(name = "Text Type") + 
  facet_wrap(~ Session,
             labeller = as_labeller(c(
               "Session 1" = "Immediate Post-test",
               "Session 2" = "Delayed Post-test"
             ))) +
  labs(title = "Form Recognition") + 
  theme(
    plot.title = element_text(size = 22, face = "bold", hjust = 0.5),
    strip.text = element_text(size = 18, face = "bold"),
    axis.title.x = element_text(size = 18, face = "bold"),
    axis.title.y = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14)
  )

print(p2)

### How can we show p-value* and effect sizes? In-Progress####

##Shapiro-Wilk Normality Test (Just In Case)##
# Shapiro-Wilk for Session 1 by Emotion
shapiro.test(FormRecognition[FormRecognition$Emotion == "Negative", ]$`Session 1`)  # p =.002**
shapiro.test(FormRecognition[FormRecognition$Emotion == "Neutral", ]$`Session 1`)   # < .001***
shapiro.test(FormRecognition[FormRecognition$Emotion == "Positive", ]$`Session 1`)  # < .001***

# Shapiro-Wilk for Session 2 by Emotion
shapiro.test(FormRecognition[FormRecognition$Emotion == "Negative", ]$`Session 2`)  # p =.004**
shapiro.test(FormRecognition[FormRecognition$Emotion == "Neutral", ]$`Session 2`)   # < .001***
shapiro.test(FormRecognition[FormRecognition$Emotion == "Positive", ]$`Session 2`)  # < .001***

# Levene's tests
# 1. Levene's Test across Sessions (Session 1 vs Session 2) # p =  0.6316
car::leveneTest(FormRecognition_long$Score, FormRecognition_long$Session, center = median)
# 2. Levene's Test across Emotions (Negative / Neutral / Positive) # p = 0.2075
car::leveneTest(FormRecognition_long$Score, FormRecognition_long$Emotion, center = median)
# 3. Levene's Test across Emotion × Session combinations # p = 0.4382
car::leveneTest(FormRecognition_long$Score, interaction(FormRecognition_long$Emotion, FormRecognition_long$Session), center = median)

### Within (Emotion) x Within (Session) (RM ANOVA) ####
library(ez)

ez_results <- ezANOVA(
  data = FormRecognition_long,             
  dv = .(Score),                 
  wid = .(Participant),          
  within = .(Emotion, Session),     # ✅ Two within-subjects factors
  type = 2,
  return_aov = TRUE,
  detailed = TRUE
)

print(ez_results)

#NOT SIGNIFICANT, no need to condcut follow-up tests (JUst IN CASE)####
##T-test
# Load library
library(dplyr)

###T-test Session 1 + Session 2 Combined###

# Step 1: Filter Session 1 and 2
data_s1s2 <- FormRecognition_long %>%
  filter(Session %in% c("Session 1", "Session 2"))

# Step 2: Sum scores across sessions for each Participant × Emotion
combined_scores_FR <- data_s1s2 %>%
  group_by(Participant, Emotion) %>%
  summarise(Score = sum(Score), .groups = "drop")

# Step 3: Pairwise t-test
pairwise.t.test(
  x = combined_scores$Score,
  g = combined_scores$Emotion,
  paired = TRUE,
  p.adjust.method = "bonferroni"
)

##Effect Sizes for Each Text (Session 1 +Session 2 Combined)##
library(tidyverse)
library(effsize)

# Negative vs Neutral
data_neg_vs_neu <- combined_scores_FR %>%
  filter(Emotion %in% c("Negative", "Neutral")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_neu$Score, data_neg_vs_neu$Emotion, paired = TRUE)

# Negative vs Positive
data_neg_vs_pos <- combined_scores_FR %>%
  filter(Emotion %in% c("Negative", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neg_vs_pos$Score, data_neg_vs_pos$Emotion, paired = TRUE)

# Negative vs Neutral
data_neu_vs_pos <- combined_scores_FR %>%
  filter(Emotion %in% c("Neutral", "Positive")) %>%
  droplevels()

effsize::cohen.d(data_neu_vs_pos$Score, data_neu_vs_pos$Emotion, paired = TRUE)

##Check potential outliers##
# Save standardized residuals
model_vocab <- lm(Score ~ Emotion * Session, data = FormRecognition_long)
FormRecognition_long$standres_vocab <- rstandard(model_vocab)
#>3#
# Number of outliers
sum(abs(FormRecognition_long$standres_vocab) > 3)
# Row indices of outliers
which(abs(FormRecognition_long$standres_vocab) > 3)
# View full rows of those outliers
FormRecognition_long[which(abs(FormRecognition_long$standres_vocab) > 3), ]
